{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport cv2\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\ntraining_set_path = \"../input/devnagari_handwritten_characters/training_data\"\ntesting_set_path = \"../input/devnagari_handwritten_characters/testing_data\"\nclass_labels = []","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def clean_data(image_dir_path):\n    print(f\"Cleaning {image_dir_path}\")\n    numpy_array_list = []\n    instances = 0\n    image_classes = sorted(os.listdir(image_dir_path))\n    for current_class in image_classes:\n        current_image_directory = f\"{image_dir_path}/{current_class}\";\n        print(f'Processing {current_class}')\n        image_list = os.listdir(current_image_directory)\n        label = current_class.split(\"_\")\n        label = label[1] if len(label) == 2 else label[2]\n        class_labels.append(label) if class_labels.count(label) == 0 else None\n        for image in image_list:\n            instances += 1\n            print(f'Processing {instances} records', end=\"\\r\")\n            image = cv2.imread(current_image_directory + \"/\" + image)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            image = tf.keras.utils.normalize(image, axis=1)\n            numpy_array_list.append((image,label))\n    np.random.shuffle(numpy_array_list)\n    return np.asarray(numpy_array_list)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data():\n    training_dataset = clean_data(training_set_path)\n    testing_dataset = clean_data(testing_set_path)\n    labels = class_labels\n    training_values = [element[0] for element in training_dataset]\n    training_labels = [labels.index(element[1]) for element in training_dataset]\n    testing_values = [element[0] for element in testing_dataset]\n    testing_labels = [labels.index(element[1]) for element in testing_dataset]\n    return training_values, training_labels, testing_values, testing_labels","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(64, activation='relu'))\n    model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(46, activation='softmax'))\n    return model","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_graph(history, epochs):\n    plt.style.use('seaborn-whitegrid')\n    \n    # Accuracy x epoch\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model Accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.yticks(np.arange(0, 1.05, step=0.05))\n    plt.xticks(np.arange(0, epochs, step=1))\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('train-test.png', bbox_inches='tight')\n\n    # Loss x epoch\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.yticks(np.arange(0, 1.05, step=0.05))\n    plt.xticks(np.arange(0, epochs, step=1))\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('train-loss.png', bbox_inches='tight')","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_data(epochs):\n    model = get_model()\n    train_images, train_labels, test_images, test_labels = get_data()\n    train_images = np.reshape(train_images, (78200, 32, 32, 1))\n    test_images = np.reshape(test_images, (13800, 32, 32, 1))\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    model.summary()\n    history = model.fit(train_images, train_labels, epochs=epochs, validation_data=(test_images, test_labels))\n    draw_graph(history, epochs)\n    test_loss, test_acc = model.evaluate(test_images, test_labels)\n    print('Accuracy : {}'.format(test_acc))\n    print('Loss : {}'.format(test_loss))\n","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data(10)","execution_count":41,"outputs":[{"output_type":"stream","text":"Cleaning ../input/devnagari_handwritten_characters/training_data\nProcessing character_10_yna\nProcessing character_11_taamatar\nProcessing character_12_thaa\nProcessing character_13_daa\nProcessing character_14_dhaa\nProcessing character_15_adna\nProcessing character_16_tabala\nProcessing character_17_tha\nProcessing character_18_da\nProcessing character_19_dha\nProcessing character_1_ka\nProcessing character_20_na\nProcessing character_21_pa\nProcessing character_22_pha\nProcessing character_23_ba\nProcessing character_24_bha\nProcessing character_25_ma\nProcessing character_26_yaw\nProcessing character_27_ra\nProcessing character_28_la\nProcessing character_29_waw\nProcessing character_2_kha\nProcessing character_30_motosaw\nProcessing character_31_petchiryakha\nProcessing character_32_patalosaw\nProcessing character_33_ha\nProcessing character_34_chhya\nProcessing character_35_tra\nProcessing character_36_gya\nProcessing character_3_ga\nProcessing character_4_gha\nProcessing character_5_kna\nProcessing character_6_cha\nProcessing character_7_chha\nProcessing character_8_ja\nProcessing character_9_jha\nProcessing digit_0ecords\nProcessing digit_1ecords\nProcessing digit_2ecords\nProcessing digit_3ecords\nProcessing digit_4ecords\nProcessing digit_5ecords\nProcessing digit_6ecords\nProcessing digit_7ecords\nProcessing digit_8ecords\nProcessing digit_9ecords\nCleaning ../input/devnagari_handwritten_characters/testing_data\nProcessing character_10_yna\nProcessing character_11_taamatar\nProcessing character_12_thaa\nProcessing character_13_daa\nProcessing character_14_dhaa\nProcessing character_15_adna\nProcessing character_16_tabala\nProcessing character_17_tha\nProcessing character_18_da\nProcessing character_19_dha\nProcessing character_1_ka\nProcessing character_20_na\nProcessing character_21_pa\nProcessing character_22_pha\nProcessing character_23_ba\nProcessing character_24_bha\nProcessing character_25_ma\nProcessing character_26_yaw\nProcessing character_27_ra\nProcessing character_28_la\nProcessing character_29_waw\nProcessing character_2_kha\nProcessing character_30_motosaw\nProcessing character_31_petchiryakha\nProcessing character_32_patalosaw\nProcessing character_33_ha\nProcessing character_34_chhya\nProcessing character_35_tra\nProcessing character_36_gya\nProcessing character_3_ga\nProcessing character_4_gha\nProcessing character_5_kna\nProcessing character_6_cha\nProcessing character_7_chha\nProcessing character_8_ja\nProcessing character_9_jha\nProcessing digit_0ecords\nProcessing digit_1ecords\nProcessing digit_2ecords\nProcessing digit_3ecords\nProcessing digit_4ecords\nProcessing digit_5ecords\nProcessing digit_6ecords\nProcessing digit_7ecords\nProcessing digit_8ecords\nProcessing digit_9ecords\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_12 (Conv2D)           (None, 30, 30, 32)        320       \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 13, 13, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 4, 4, 64)          36928     \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 64)                65600     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 46)                2990      \n=================================================================\nTotal params: 124,334\nTrainable params: 124,334\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 78200 samples, validate on 13800 samples\nEpoch 1/10\n78200/78200 [==============================] - 12s 147us/sample - loss: 0.8932 - acc: 0.7407 - val_loss: 0.2221 - val_acc: 0.9310\nEpoch 2/10\n78200/78200 [==============================] - 11s 140us/sample - loss: 0.2969 - acc: 0.9071 - val_loss: 0.1569 - val_acc: 0.9525\nEpoch 3/10\n78200/78200 [==============================] - 11s 139us/sample - loss: 0.2035 - acc: 0.9368 - val_loss: 0.1361 - val_acc: 0.9580\nEpoch 4/10\n78200/78200 [==============================] - 11s 142us/sample - loss: 0.1593 - acc: 0.9490 - val_loss: 0.1286 - val_acc: 0.9620\nEpoch 5/10\n78200/78200 [==============================] - 11s 141us/sample - loss: 0.1301 - acc: 0.9586 - val_loss: 0.1012 - val_acc: 0.9711\nEpoch 6/10\n78200/78200 [==============================] - 12s 148us/sample - loss: 0.1065 - acc: 0.9655 - val_loss: 0.1011 - val_acc: 0.9709\nEpoch 7/10\n78200/78200 [==============================] - 11s 142us/sample - loss: 0.0956 - acc: 0.9685 - val_loss: 0.0870 - val_acc: 0.9757\nEpoch 8/10\n78200/78200 [==============================] - 11s 140us/sample - loss: 0.0828 - acc: 0.9734 - val_loss: 0.0832 - val_acc: 0.9755\nEpoch 9/10\n78200/78200 [==============================] - 11s 140us/sample - loss: 0.0722 - acc: 0.9759 - val_loss: 0.0938 - val_acc: 0.9747\nEpoch 10/10\n78200/78200 [==============================] - 11s 140us/sample - loss: 0.0640 - acc: 0.9790 - val_loss: 0.0947 - val_acc: 0.9756\n13800/13800 [==============================] - 1s 59us/sample - loss: 0.0947 - acc: 0.9756\nAccuracy : 0.9755797386169434\nLoss : 0.09467861246684586\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}